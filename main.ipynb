{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "I5GOpRY8iceH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121074,
     "status": "ok",
     "timestamp": 1744696153033,
     "user": {
      "displayName": "Ï≤úÏû¨Ïõê",
      "userId": "10314458299258158887"
     },
     "user_tz": -540
    },
    "id": "I5GOpRY8iceH",
    "outputId": "59ea41f2-0a57-4455-c4ae-89b38873f9fb"
   },
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd08f52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-11T09:04:12.198519Z",
     "iopub.status.busy": "2025-04-11T09:04:12.198421Z",
     "iopub.status.idle": "2025-04-11T09:04:15.339455Z",
     "shell.execute_reply": "2025-04-11T09:04:15.339113Z",
     "shell.execute_reply.started": "2025-04-11T09:04:12.198511Z"
    },
    "executionInfo": {
     "elapsed": 13561,
     "status": "ok",
     "timestamp": 1744696166669,
     "user": {
      "displayName": "Ï≤úÏû¨Ïõê",
      "userId": "10314458299258158887"
     },
     "user_tz": -540
    },
    "id": "6dd08f52",
    "outputId": "9861d3a5-ad07-48e8-a7a5-716d079f073f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Install mish-cuda to speed up training and inference. More importantly, replace the naive Mish with MishCuda will give a ~1.5G memory saving during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[path_manager] + C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\n",
      " üëÄ  ÌòÑÏû¨ sys.path[0] : C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\n",
      " üìÇ  root ÎÇ¥Ïö©: ['.gitignore', 'benchmark.py', 'config', 'data', 'demo.py', 'eval.py', 'evaluator', 'models', 'README.md', 'test.py']\n",
      "üìÇ  root/models/yoloh : True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\AerialObjectDetection\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "c:\\Users\\user\\anaconda3\\envs\\AerialObjectDetection\\lib\\site-packages\\timm\\models\\registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\\models\\backbone\\convnext.py:204: UserWarning: Overwriting convnext_tiny in registry with models.backbone.convnext.convnext_tiny. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_tiny(pretrained=False, res_dilation=False, **kwargs):\n",
      "C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\\models\\backbone\\convnext.py:211: UserWarning: Overwriting convnext_small in registry with models.backbone.convnext.convnext_small. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_small(pretrained=False, res_dilation=False, **kwargs):\n",
      "C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\\models\\backbone\\convnext.py:218: UserWarning: Overwriting convnext_base in registry with models.backbone.convnext.convnext_base. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_base(pretrained=False, res_dilation=False, in_22k=False, **kwargs):\n",
      "C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\\models\\backbone\\convnext.py:228: UserWarning: Overwriting convnext_large in registry with models.backbone.convnext.convnext_large. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_large(pretrained=False, res_dilation=False, in_22k=False, **kwargs):\n",
      "C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\\models\\backbone\\convnext.py:238: UserWarning: Overwriting convnext_xlarge in registry with models.backbone.convnext.convnext_xlarge. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_xlarge(pretrained=False, res_dilation=False, in_22k=False, **kwargs):\n",
      "Install mish-cuda to speed up training and inference. More importantly, replace the naive Mish with MishCuda will give a ~1.5G memory saving during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[path_manager] - C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\\models\\backbone\\convnext.py:204: UserWarning: Overwriting convnext_tiny in registry with models.backbone.convnext.convnext_tiny. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_tiny(pretrained=False, res_dilation=False, **kwargs):\n",
      "C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\\models\\backbone\\convnext.py:211: UserWarning: Overwriting convnext_small in registry with models.backbone.convnext.convnext_small. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_small(pretrained=False, res_dilation=False, **kwargs):\n",
      "C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\\models\\backbone\\convnext.py:218: UserWarning: Overwriting convnext_base in registry with models.backbone.convnext.convnext_base. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_base(pretrained=False, res_dilation=False, in_22k=False, **kwargs):\n",
      "C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\\models\\backbone\\convnext.py:228: UserWarning: Overwriting convnext_large in registry with models.backbone.convnext.convnext_large. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_large(pretrained=False, res_dilation=False, in_22k=False, **kwargs):\n",
      "C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YOLOH\\models\\backbone\\convnext.py:238: UserWarning: Overwriting convnext_xlarge in registry with models.backbone.convnext.convnext_xlarge. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_xlarge(pretrained=False, res_dilation=False, in_22k=False, **kwargs):\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from utility import *\n",
    "from ultralytics import settings\n",
    "from registry import get_model, get_pipeline\n",
    "#settings.update({'datasets_dir': os.path.abspath('.')})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c883b28-7e26-40bb-9d4f-b8a384ed40d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:04:15.339909Z",
     "iopub.status.busy": "2025-04-11T09:04:15.339783Z",
     "iopub.status.idle": "2025-04-11T09:04:15.342378Z",
     "shell.execute_reply": "2025-04-11T09:04:15.342181Z",
     "shell.execute_reply.started": "2025-04-11T09:04:15.339901Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1744696166729,
     "user": {
      "displayName": "Ï≤úÏû¨Ïõê",
      "userId": "10314458299258158887"
     },
     "user_tz": -540
    },
    "id": "3c883b28-7e26-40bb-9d4f-b8a384ed40d8"
   },
   "outputs": [],
   "source": [
    "project_name = 'Object Detection'\n",
    "# dataset_root Í∞Ä ÏÉÅÎåÄÍ≤ΩÎ°úÏùº Í≤ΩÏö∞ colab ÌôòÍ≤ΩÏóêÏÑúÎäî Î¨¥Ï°∞Í±¥ ÏïûÏóê datasets Î•º Î∂ôÏó¨ÏÑú Ï∞æÎäî Î¨∏Ï†úÍ∞Ä ÏûàÏùå\n",
    "dataset_root = 'Datasets'\n",
    "output_dir = 'output'\n",
    "dataset_names = ['COCO_airplane']\n",
    "model_names = ['YoloOW', 'yoloh18', 'yoloh50', 'yoloh101' ]\n",
    "iterations = [1, 5]\n",
    "epochs = 5\n",
    "early_stop = 20\n",
    "batch_size = 16\n",
    "image_size = 640\n",
    "optimizer = 'AdamW'\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "optim_args = {'optimizer': optimizer, 'lr': lr, 'momentum': momentum, 'weight_decay': weight_decay}\n",
    "devices = [0]\n",
    "device = torch.device(\"cuda:\"+str(devices[0])) if len(devices)>0 else torch.device(\"cpu\")\n",
    "train_split = 0.6\n",
    "val_split = 0.2\n",
    "test_split = 0.2\n",
    "num_workers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3564f553-e7b4-45cd-9171-465418f355ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-11T09:04:15.342815Z",
     "iopub.status.busy": "2025-04-11T09:04:15.342678Z",
     "iopub.status.idle": "2025-04-11T09:04:20.532205Z",
     "shell.execute_reply": "2025-04-11T09:04:20.531371Z",
     "shell.execute_reply.started": "2025-04-11T09:04:15.342803Z"
    },
    "executionInfo": {
     "elapsed": 5894784,
     "status": "ok",
     "timestamp": 1744702065603,
     "user": {
      "displayName": "Ï≤úÏû¨Ïõê",
      "userId": "10314458299258158887"
     },
     "user_tz": -540
    },
    "id": "3564f553-e7b4-45cd-9171-465418f355ae",
    "outputId": "24fde293-4a80-49a9-ed27-3892b0e3e555",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Start Time: 250427_171440\n",
      "(Iter 1)\n",
      "Dataset: COCO_airplane (1/1)\n",
      "YoloOW (1/4) (Iter 1) Dataset: COCO_airplane (1/1) [YoloOW] Using config ‚Üí C:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\Models\\YoloOW\\cfg\\training\\yoloOW.yaml\n",
      "\n",
      "[trainer] üîç Checking anchor fit to dataset...\n",
      "[YOLOTxtDataset] Caching labels for anchor check...\n",
      "[trainer] ‚ö†Ô∏è Low anchor fit (0.12 < 4.0). Consider running autoanchor.\n",
      "==============================\n",
      "Optimizer: adamw\n",
      "--momentum: 0.9\n",
      "--weight_decay: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[YoloOW] Epoch 1/10:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] first batch target rows = 16\n",
      "[DEBUG] first 5 targets:\n",
      " tensor([[0.00000, 0.00000, 0.36098, 0.40695, 0.51108, 0.28026],\n",
      "        [1.00000, 0.00000, 0.44410, 0.28651, 0.88483, 0.28090],\n",
      "        [2.00000, 0.00000, 0.49249, 0.51572, 0.96752, 0.71235],\n",
      "        [3.00000, 0.00000, 0.49597, 0.50713, 0.90334, 0.38318],\n",
      "        [4.00000, 0.00000, 0.58469, 0.24538, 0.83061, 0.49075]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\utility\\trainer.py:114: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Scalar.cpp:23.)\n",
      "  total_loss += loss.item()\n",
      "[YoloOW] Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:29<00:00,  1.38it/s, Loss=2.1312, box=0.123, obj=0.010, cls=0.000, total loss=0.133, lr=0.000195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YoloOW] ‚úÖ Epoch 1/10 complete in 36.23s | Avg Loss: 1.7072\n",
      "\n",
      "[YoloOW] üìä Running evaluation after epoch 1 ...\n",
      "[validate_yoloow_model] ‚úÖ  Avg Loss  (box/obj/cls/total): 0.0940 / 0.0134 / 0.0000 / 0.1074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[YoloOW] Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:26<00:00,  1.53it/s, Loss=1.7718, box=0.107, obj=0.004, cls=0.000, total loss=0.111, lr=0.000395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YoloOW] ‚úÖ Epoch 2/10 complete in 33.50s | Avg Loss: 1.4924\n",
      "\n",
      "[YoloOW] üìä Running evaluation after epoch 2 ...\n",
      "[validate_yoloow_model] ‚úÖ  Avg Loss  (box/obj/cls/total): 0.0743 / 0.0062 / 0.0000 / 0.0805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[YoloOW] Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:26<00:00,  1.54it/s, Loss=1.5272, box=0.092, obj=0.003, cls=0.000, total loss=0.095, lr=0.000595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YoloOW] ‚úÖ Epoch 3/10 complete in 33.25s | Avg Loss: 1.1230\n",
      "\n",
      "[YoloOW] üìä Running evaluation after epoch 3 ...\n",
      "[validate_yoloow_model] ‚úÖ  Avg Loss  (box/obj/cls/total): 0.0729 / 0.0033 / 0.0000 / 0.0762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[YoloOW] Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:26<00:00,  1.54it/s, Loss=1.8300, box=0.112, obj=0.002, cls=0.000, total loss=0.114, lr=0.000795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YoloOW] ‚úÖ Epoch 4/10 complete in 33.26s | Avg Loss: 1.2350\n",
      "\n",
      "[YoloOW] üìä Running evaluation after epoch 4 ...\n",
      "[validate_yoloow_model] ‚úÖ  Avg Loss  (box/obj/cls/total): 0.0686 / 0.0032 / 0.0000 / 0.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[YoloOW] Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:33<00:00,  1.23it/s, Loss=1.9204, box=0.119, obj=0.001, cls=0.000, total loss=0.120, lr=0.000995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YoloOW] ‚úÖ Epoch 5/10 complete in 40.08s | Avg Loss: 1.1103\n",
      "\n",
      "[YoloOW] üìä Running evaluation after epoch 5 ...\n",
      "[validate_yoloow_model] ‚úÖ  Avg Loss  (box/obj/cls/total): 0.0736 / 0.0018 / 0.0000 / 0.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[YoloOW] Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:52<00:00,  1.29s/it, Loss=1.7089, box=0.105, obj=0.002, cls=0.000, total loss=0.107, lr=0.001000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YoloOW] ‚úÖ Epoch 6/10 complete in 59.30s | Avg Loss: 1.1977\n",
      "\n",
      "[YoloOW] üìä Running evaluation after epoch 6 ...\n",
      "[validate_yoloow_model] ‚úÖ  Avg Loss  (box/obj/cls/total): 0.0687 / 0.0021 / 0.0000 / 0.0709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[YoloOW] Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:44<00:00,  1.10s/it, Loss=1.6171, box=0.100, obj=0.001, cls=0.000, total loss=0.101, lr=0.000691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YoloOW] ‚úÖ Epoch 7/10 complete in 51.56s | Avg Loss: 1.1876\n",
      "\n",
      "[YoloOW] üìä Running evaluation after epoch 7 ...\n",
      "[validate_yoloow_model] ‚úÖ  Avg Loss  (box/obj/cls/total): 0.0742 / 0.0029 / 0.0000 / 0.0771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[YoloOW] Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:52<00:00,  1.27s/it, Loss=1.4535, box=0.089, obj=0.002, cls=0.000, total loss=0.091, lr=0.000412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YoloOW] ‚úÖ Epoch 8/10 complete in 58.90s | Avg Loss: 1.1953\n",
      "\n",
      "[YoloOW] üìä Running evaluation after epoch 8 ...\n",
      "[validate_yoloow_model] ‚úÖ  Avg Loss  (box/obj/cls/total): 0.0691 / 0.0021 / 0.0000 / 0.0712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[YoloOW] Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [01:13<00:00,  1.80s/it, Loss=0.7316, box=0.044, obj=0.002, cls=0.000, total loss=0.046, lr=0.000191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YoloOW] ‚úÖ Epoch 9/10 complete in 81.37s | Avg Loss: 1.2159\n",
      "\n",
      "[YoloOW] üìä Running evaluation after epoch 9 ...\n",
      "[validate_yoloow_model] ‚úÖ  Avg Loss  (box/obj/cls/total): 0.0694 / 0.0019 / 0.0000 / 0.0713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[YoloOW] Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:37<00:00,  1.10it/s, Loss=1.3899, box=0.084, obj=0.003, cls=0.000, total loss=0.087, lr=0.000049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YoloOW] ‚úÖ Epoch 10/10 complete in 43.87s | Avg Loss: 1.1458\n",
      "\n",
      "[YoloOW] üìä Running evaluation after epoch 10 ...\n",
      "[validate_yoloow_model] ‚úÖ  Avg Loss  (box/obj/cls/total): 0.0680 / 0.0019 / 0.0000 / 0.0699\n",
      "[validate_yoloow_model] ‚úÖ  Avg Loss  (box/obj/cls/total): 0.0680 / 0.0019 / 0.0000 / 0.0699\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m ex_dict \u001b[38;5;241m=\u001b[39m train_fn(ex_dict)\n\u001b[0;32m     45\u001b[0m ex_dict \u001b[38;5;241m=\u001b[39m eval_fn(ex_dict)\n\u001b[1;32m---> 46\u001b[0m ex_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtest_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m ex_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain-Test Time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer() \u001b[38;5;241m-\u001b[39m start\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m#################\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\AerialObjectDetection\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\Aerial Object Detection\\AERIAL_OBJECT_DETECTION\\utility\\yoloow_utils.py:231\u001b[0m, in \u001b[0;36mtest_yoloow_model\u001b[1;34m(ex_dict)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# AP Í≥ÑÏÇ∞\u001b[39;00m\n\u001b[0;32m    229\u001b[0m stats \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mcat(x, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x[\u001b[38;5;241m0\u001b[39m], torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(x, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    230\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mstats)]\n\u001b[1;32m--> 231\u001b[0m precision, recall, ap, f1, ap_class \u001b[38;5;241m=\u001b[39m ap_per_class(\u001b[38;5;241m*\u001b[39mstats)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# BoxResults ÏÉùÏÑ±\u001b[39;00m\n\u001b[0;32m    234\u001b[0m ap50 \u001b[38;5;241m=\u001b[39m ap[:, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "from utility.utils import control_random_seed, update_dataset_paths, format_measures, merge_and_update_df\n",
    "\n",
    "\n",
    "Experiments_Time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "print('Experiment Start Time:',Experiments_Time)\n",
    "\n",
    "ex_dict = {}\n",
    "ex_dict['Experiment Time'] = Experiments_Time;ex_dict['Epochs'] = epochs;\n",
    "ex_dict['Batch Size'] = batch_size;\n",
    "ex_dict['Early Stop'] = early_stop;\n",
    "ex_dict['Device'] = device\n",
    "ex_dict['Optimizer'] = optimizer;\n",
    "ex_dict['LR']=optim_args['lr']; ex_dict['Weight Decay']=optim_args['weight_decay'];ex_dict['Momentum']=optim_args['momentum'];\n",
    "#ex_dict['Hyp'] = dict(lr0=ex_dict['LR'], momentum=ex_dict['Momentum'], weight_decay=ex_dict['Weight Decay'])\n",
    "ex_dict['Image Size'] = image_size\n",
    "ex_dict['Output Dir'] = output_dir\n",
    "ex_dict['Num Workers'] = num_workers\n",
    "\n",
    "for iteration in range(iterations[0], iterations[1]+1):\n",
    "    print(f'(Iter {iteration})')\n",
    "    seed = iteration\n",
    "    ex_dict['Iteration'] = iteration\n",
    "    for j, Dataset_Name in enumerate(dataset_names):\n",
    "        print(f'Dataset: {Dataset_Name} ({j+1}/{len(dataset_names)})');\n",
    "        control_random_seed(seed)\n",
    "        data_yaml_path = f\"{dataset_root}/{Dataset_Name}/data_iter_{iteration:02d}.yaml\"\n",
    "        with open(data_yaml_path, 'r') as f:\n",
    "            data_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        ex_dict['Dataset Name'] = Dataset_Name; ex_dict['Data Config'] = data_yaml_path; ex_dict['Number of Classes'] = data_config['nc']; ex_dict['Class Names'] = data_config['names'];\n",
    "        ex_dict['Split Size'] = f\"{data_config['train_count']}/{data_config['val_count']}/{data_config['test_count']}\"\n",
    "        update_dataset_paths(dataset_root, Dataset_Name, iteration)\n",
    "        \n",
    "        for k, model_name in enumerate(model_names):\n",
    "            print(f'{model_name} ({k+1}/{len(model_names)}) (Iter {iteration})', end=' ')\n",
    "            print(f'Dataset: {Dataset_Name} ({j+1}/{len(dataset_names)})', end=' ')\n",
    "            control_random_seed(seed)\n",
    "            \n",
    "            model = get_model(model_name, ex_dict)\n",
    "            train_fn, eval_fn, test_fn = get_pipeline(model_name)\n",
    "\n",
    "            ex_dict['Model Name'] = model_name; ex_dict['Model']=model;\n",
    "            start = timeit.default_timer()\n",
    "\n",
    "            ex_dict = train_fn(ex_dict)\n",
    "            ex_dict = eval_fn(ex_dict)\n",
    "            ex_dict = test_fn(ex_dict)\n",
    "\n",
    "            ex_dict['Train-Test Time'] = timeit.default_timer() - start\n",
    "            #################\n",
    "            if ex_dict.get('Test Results') is None:\n",
    "                raise RuntimeError(\"ÌèâÍ∞Ä Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§. ÏúÑÏùò Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏Î•º Ï∞∏Í≥†Ìï¥ ÏõêÏù∏Î∂ÄÌÑ∞ Ìï¥Í≤∞ÌïòÏÑ∏Ïöî.\")\n",
    "\n",
    "            eval_dict = format_measures(ex_dict.get('Test Results'))\n",
    "            output_csv = f\"{ex_dict['Experiment Time']}_{project_name}_Results.csv\"\n",
    "            merge_and_update_df(ex_dict, eval_dict, output_csv, exclude_columns=['Model', 'Train Results', 'Test Results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0aa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä: True\n",
      "CUDA ÎîîÎ∞îÏù¥Ïä§ Ïàò: 1\n",
      "ÌòÑÏû¨ ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: 0\n",
      "ÎîîÎ∞îÏù¥Ïä§ Ïù¥Î¶Ñ: NVIDIA GeForce RTX 5060 Ti\n",
      "PyTorch CUDA Î≤ÑÏ†Ñ: 12.8\n",
      "PyTorch Î≤ÑÏ†Ñ: 2.8.0.dev20250420+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA ÎîîÎ∞îÏù¥Ïä§ Ïàò: {torch.cuda.device_count()}\")\n",
    "print(f\"ÌòÑÏû¨ ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: {torch.cuda.current_device()}\")\n",
    "print(f\"ÎîîÎ∞îÏù¥Ïä§ Ïù¥Î¶Ñ: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"PyTorch CUDA Î≤ÑÏ†Ñ: {torch.version.cuda}\")\n",
    "print(f\"PyTorch Î≤ÑÏ†Ñ: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3128ef8a-7dd8-4329-a92d-4e73283bfac4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1744690106616,
     "user": {
      "displayName": "Ï≤úÏû¨Ïõê",
      "userId": "10314458299258158887"
     },
     "user_tz": -540
    },
    "id": "3128ef8a-7dd8-4329-a92d-4e73283bfac4",
    "outputId": "e9d646f5-312a-4f0e-885c-af9229b5ed87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /root/.config/Ultralytics/settings.json: No such file or directory\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AerialObjectDetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
