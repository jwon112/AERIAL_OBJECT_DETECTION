{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49A5we4LiFJ4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17985,
     "status": "ok",
     "timestamp": 1744695937273,
     "user": {
      "displayName": "천재원",
      "userId": "10314458299258158887"
     },
     "user_tz": -540
    },
    "id": "49A5we4LiFJ4",
    "outputId": "0be51a89-c9d8-4d9c-e299-537bfbebba87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48pS5iluiNTX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1744695937759,
     "user": {
      "displayName": "천재원",
      "userId": "10314458299258158887"
     },
     "user_tz": -540
    },
    "id": "48pS5iluiNTX",
    "outputId": "0646beb1-0461-446d-b549-6e252090b015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 경로: /content\n",
      "현재 경로: /content/drive/MyDrive/Colab Notebooks/AerialObjectDetection/Aerial_Object_Detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"현재 경로:\", os.getcwd())\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/AerialObjectDetection/Aerial_Object_Detection')\n",
    "print(\"현재 경로:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e912340-df45-4ee4-a15c-99d967f947c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:03:37.632646Z",
     "iopub.status.busy": "2025-04-11T09:03:37.631259Z",
     "iopub.status.idle": "2025-04-11T09:03:37.897528Z",
     "shell.execute_reply": "2025-04-11T09:03:37.897173Z",
     "shell.execute_reply.started": "2025-04-11T09:03:37.632562Z"
    },
    "executionInfo": {
     "elapsed": 3255,
     "status": "ok",
     "timestamp": 1744695942377,
     "user": {
      "displayName": "천재원",
      "userId": "10314458299258158887"
     },
     "user_tz": -540
    },
    "id": "5e912340-df45-4ee4-a15c-99d967f947c0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import yaml\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_random_splits(data_dir, n_splits=5, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):\n",
    "    \"\"\"\n",
    "    단일 데이터 경로에서 이미지와 라벨 데이터셋을 N개의 랜덤 train/val/test로 분할하고 관련 파일을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): 데이터 디렉토리 경로 (images, labels 폴더와 data.yaml 파일을 포함)\n",
    "        n_splits (int): 생성할 데이터셋 분할 수\n",
    "        train_ratio (float): 학습 데이터 비율\n",
    "        val_ratio (float): 검증 데이터 비율\n",
    "        test_ratio (float): 테스트 데이터 비율\n",
    "    \"\"\"\n",
    "    # 비율 합이 1인지 확인\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-10, \"비율의 합은 1이어야 합니다\"\n",
    "\n",
    "    # 경로 설정\n",
    "    images_dir = os.path.join(data_dir, 'images')\n",
    "    labels_dir = os.path.join(data_dir, 'labels')\n",
    "    yaml_path = os.path.join(data_dir, 'data.yaml')\n",
    "\n",
    "    # 디렉토리 존재 확인\n",
    "    if not os.path.exists(images_dir) or not os.path.exists(labels_dir):\n",
    "        print(f\"경고: {data_dir}에 images 또는 labels 폴더가 없습니다. 건너뜁니다.\")\n",
    "        return\n",
    "\n",
    "    # 이미지 파일 목록 가져오기 (확장자는 필요에 따라 수정)\n",
    "    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(glob(os.path.join(images_dir, ext)))\n",
    "\n",
    "    # 이미지 파일명만 추출 (확장자 포함)\n",
    "    image_filenames = [os.path.basename(f) for f in image_files]\n",
    "\n",
    "    # 해당 이미지 파일에 대응하는 라벨 파일이 있는지 확인\n",
    "    valid_samples = []\n",
    "    for img_filename in image_filenames:\n",
    "        # 이미지 파일명에서 확장자를 제거하고 라벨 파일 확장자 추가\n",
    "        base_name = os.path.splitext(img_filename)[0]\n",
    "        label_path = os.path.join(labels_dir, base_name + '.txt')\n",
    "\n",
    "        # 라벨 파일이 존재하면 유효한 샘플로 간주\n",
    "        if os.path.exists(label_path):\n",
    "            valid_samples.append((img_filename, base_name + '.txt'))\n",
    "\n",
    "    if not valid_samples:\n",
    "        print(f\"오류: {data_dir}에서 유효한 샘플을 찾을 수 없습니다.\")\n",
    "        return\n",
    "\n",
    "    # data.yaml 파일 불러오기\n",
    "    try:\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data_yaml = yaml.safe_load(f)\n",
    "            nc = data_yaml.get('nc', 0)\n",
    "            names = data_yaml.get('names', [])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"경고: {yaml_path} 파일을 찾을 수 없습니다. nc와 names는 기본값으로 설정됩니다.\")\n",
    "        nc = 0\n",
    "        names = []\n",
    "\n",
    "    print(f\"{data_dir}: {len(valid_samples)}개의 유효한 샘플을 찾았습니다.\")\n",
    "\n",
    "    # N개의 랜덤 분할 생성\n",
    "    for iter_idx in range(1, n_splits + 1):\n",
    "        # 데이터 세트 분할\n",
    "        random.shuffle(valid_samples)\n",
    "\n",
    "        # 먼저 train과 temp(val+test) 분할\n",
    "        train_samples, temp_samples = train_test_split(\n",
    "            valid_samples,\n",
    "            train_size=train_ratio,\n",
    "            test_size=val_ratio + test_ratio,\n",
    "            random_state=iter_idx  # 각 반복마다 다른 시드 사용\n",
    "        )\n",
    "\n",
    "        # temp를 val과 test로 분할\n",
    "        val_ratio_adjusted = val_ratio / (val_ratio + test_ratio)\n",
    "        val_samples, test_samples = train_test_split(\n",
    "            temp_samples,\n",
    "            train_size=val_ratio_adjusted,\n",
    "            test_size=1 - val_ratio_adjusted,\n",
    "            random_state=iter_idx\n",
    "        )\n",
    "\n",
    "        # 텍스트 파일 생성\n",
    "        train_txt_path = os.path.join(data_dir, f'train_iter_{iter_idx:02d}.txt')\n",
    "        val_txt_path = os.path.join(data_dir, f'val_iter_{iter_idx:02d}.txt')\n",
    "        test_txt_path = os.path.join(data_dir, f'test_iter_{iter_idx:02d}.txt')\n",
    "\n",
    "        # 학습 데이터 파일 쓰기\n",
    "        with open(train_txt_path, 'w') as f:\n",
    "            for img_file, _ in train_samples:\n",
    "                img_path = os.path.join('images', img_file)  # 상대 경로 사용\n",
    "                f.write(f\"{img_path}\\n\")\n",
    "\n",
    "        # 검증 데이터 파일 쓰기\n",
    "        with open(val_txt_path, 'w') as f:\n",
    "            for img_file, _ in val_samples:\n",
    "                img_path = os.path.join('images', img_file)  # 상대 경로 사용\n",
    "                f.write(f\"{img_path}\\n\")\n",
    "\n",
    "        # 테스트 데이터 파일 쓰기\n",
    "        with open(test_txt_path, 'w') as f:\n",
    "            for img_file, _ in test_samples:\n",
    "                img_path = os.path.join('images', img_file)  # 상대 경로 사용\n",
    "                f.write(f\"{img_path}\\n\")\n",
    "\n",
    "        # YAML 파일 생성\n",
    "        output_yaml_path = os.path.join(data_dir, f'data_iter_{iter_idx:02d}.yaml')\n",
    "        yaml_content = {\n",
    "            'train': f'train_iter_{iter_idx:02d}.txt',  # 상대 경로 사용\n",
    "            'val': f'val_iter_{iter_idx:02d}.txt',      # 상대 경로 사용\n",
    "            'test': f'test_iter_{iter_idx:02d}.txt',     # 상대 경로 사용\n",
    "            'nc': nc,\n",
    "            'names': names,\n",
    "            'train_count': len(train_samples),  # 학습 이미지 개수 추가\n",
    "            'val_count': len(val_samples),      # 검증 이미지 개수 추가\n",
    "            'test_count': len(test_samples)     # 테스트 이미지 개수 추가\n",
    "        }\n",
    "\n",
    "        with open(output_yaml_path, 'w') as f:\n",
    "            yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "\n",
    "        print(f\"{data_dir} - Iteration {iter_idx} 완료: {len(train_samples)} 학습, {len(val_samples)} 검증, {len(test_samples)} 테스트\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60fc74f5-317f-4086-9a17-e613caba6415",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-11T09:03:39.960050Z",
     "iopub.status.busy": "2025-04-11T09:03:39.959513Z",
     "iopub.status.idle": "2025-04-11T09:03:39.999725Z",
     "shell.execute_reply": "2025-04-11T09:03:39.999196Z",
     "shell.execute_reply.started": "2025-04-11T09:03:39.960009Z"
    },
    "executionInfo": {
     "elapsed": 7390,
     "status": "ok",
     "timestamp": 1744695950167,
     "user": {
      "displayName": "천재원",
      "userId": "10314458299258158887"
     },
     "user_tz": -540
    },
    "id": "60fc74f5-317f-4086-9a17-e613caba6415",
    "outputId": "88b8344b-c239-4565-cae2-3505ef05953d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO_airplane\n",
      "Datasets/COCO_airplane: 1117개의 유효한 샘플을 찾았습니다.\n",
      "Datasets/COCO_airplane - Iteration 1 완료: 670 학습, 223 검증, 224 테스트\n",
      "Datasets/COCO_airplane - Iteration 2 완료: 670 학습, 223 검증, 224 테스트\n",
      "Datasets/COCO_airplane - Iteration 3 완료: 670 학습, 223 검증, 224 테스트\n",
      "Datasets/COCO_airplane - Iteration 4 완료: 670 학습, 223 검증, 224 테스트\n",
      "Datasets/COCO_airplane - Iteration 5 완료: 670 학습, 223 검증, 224 테스트\n",
      "Datasets/COCO_airplane - Iteration 6 완료: 670 학습, 223 검증, 224 테스트\n",
      "Datasets/COCO_airplane - Iteration 7 완료: 670 학습, 223 검증, 224 테스트\n",
      "Datasets/COCO_airplane - Iteration 8 완료: 670 학습, 223 검증, 224 테스트\n",
      "Datasets/COCO_airplane - Iteration 9 완료: 670 학습, 223 검증, 224 테스트\n",
      "Datasets/COCO_airplane - Iteration 10 완료: 670 학습, 223 검증, 224 테스트\n"
     ]
    }
   ],
   "source": [
    "data_dirs=['COCO_airplane']\n",
    "root = 'Datasets'\n",
    "data_dirs = os.listdir(root)\n",
    "n_splits = 10\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "for data_dir in data_dirs:\n",
    "    print(data_dir)\n",
    "    data_dir =f\"{root}/{data_dir}\"\n",
    "    create_random_splits(data_dir, n_splits, train_ratio, val_ratio, test_ratio)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AerialObjectDetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
