# utility/trainer.py

import time
import torch
from tqdm import tqdm
import numpy as np
from utility.metrics import xywh2xyxy, box_iou 
from utility.autoanchor import check_anchors as autoanchor_check_anchors
import numpy as np
import torch
from utility.metrics import box_iou

# âœ… DEBUG ë¡œê±° import
try:
    from utility.debug_logger import debug_log
except ImportError:
    def debug_log(msg, show_console=False):
        if show_console:
            print(f"[DEBUG] {msg}")

def check_anchors(dataset, model, imgsz=640, threshold=4.0):
    print("\n[trainer] ğŸ” Checking anchor fit to dataset...")
    if not hasattr(model, "anchors") or model.anchors is None:
        print("[trainer] âš ï¸ model has no `.anchors` attribute. Skipping anchor check.")
        return

    labels = np.concatenate(dataset.labels, 0)
    if labels.size == 0:
        print("[trainer] âš ï¸ No labels found in dataset. Skipping anchor check.")
        return

    # normalized w,h â†’ í”½ì…€ ë‹¨ìœ„ numpy array
    wh_np = labels[:, 3:5] * imgsz  # shape (N,2)

    # GPUì— ì˜¬ë¼ê°„ ì•µì»¤ ë²¡í„°
    anchor_vec = model.anchors.clone().view(-1, 2)  # tensor, e.g. device=cuda:0
    device = anchor_vec.device

    try:
        # 4-coords ë°•ìŠ¤ (0,0,w,h)
        b1 = torch.from_numpy(
            np.hstack([np.zeros_like(wh_np), wh_np])
        ).float().to(device)       # (N,4), .to(device) ë¡œ GPUë¡œ ì´ë™

        b2 = torch.cat([
            torch.zeros_like(anchor_vec),  # x1=0, y1=0
            anchor_vec                      # x2=aw, y2=ah
        ], dim=1)                          # (M,4) already on `device`

        # IoU ê³„ì‚°
        ious = box_iou(b1, b2)            # (N,M)
        best_per_wh = ious.max(1)[0]      # ê° gt-boxë³„ best IoU
        best_ratio = best_per_wh.mean().item()

    except Exception as e:
        print(f"[trainer] âš ï¸ Anchor check skipped: {e}")
        return

    if best_ratio < threshold:
        print(f"[trainer] âš ï¸ Low anchor fit ({best_ratio:.2f} < {threshold}). Consider running autoanchor.")
    else:
        print(f"[trainer] âœ… Anchor fit okay (mean best IoU: {best_ratio:.2f}).")

def _safe_item(val):
    """tensor ë˜ëŠ” float/int ê°’ì„ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜"""
    if hasattr(val, 'detach'):
        return val.detach().item()
    elif hasattr(val, 'item'):
        return val.item()
    else:
        return float(val)

def run_train_loop(
    model,
    train_loader,
    criterion,
    optimizer,
    scheduler,
    epochs,
    device,
    model_name="model",
    print_interval=10,
    eval_fn=None,
    ex_dict=None
):
    model.train()
    global_step = 0
    warmup_iters = min(1000, len(train_loader) * 5)  # warmup iterations

    # Store initial learning rate for logging
    for pg in optimizer.param_groups:
        pg.setdefault("initial_lr", pg["lr"])

    for epoch in range(epochs):
        start_time = time.time()
        total_loss = 0.0

        loop = tqdm(enumerate(train_loader), total=len(train_loader), desc=f"[{model_name}] Epoch {epoch+1}/{epochs}")

        for i, (imgs, targets) in loop:
            
            if i == 0 and epoch == 0:          # ìµœì´ˆ 1íšŒë§Œ
                # targets â†’ collate_fn ì— ì˜í•´ (N,6) Tensor ë˜ëŠ” 0-í¬ê¸° Tensor
                debug_log(f"first batch target rows = {targets.shape[0]}", show_console=True)
                if targets.shape[0]:
                    debug_log(f"first 5 targets:\n{targets[:5].cpu()}", show_console=True)

            imgs = imgs.to(device)
            targets = [t.to(device) for t in targets] if isinstance(targets, list) else targets.to(device)

            # Warmup
            if global_step <= warmup_iters:
                xi = [0, warmup_iters]
                for j, x in enumerate(optimizer.param_groups):
                    x['lr'] = np.interp(global_step, xi, [0.0, x['initial_lr']])
                    if 'momentum' in x:
                        x['momentum'] = np.interp(global_step, xi, [0.8, 0.937])
                if hasattr(model, "gr"):
                    model.gr = np.interp(global_step, xi, [0.0, 1.0])


            optimizer.zero_grad()
            preds = model(imgs)
            # ğŸ” LossëŠ” FPN í”¼ì²˜ë§µ(preds[1]) ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
            preds_for_loss = preds[1] if isinstance(preds, tuple) else preds
            loss, loss_items = criterion(preds_for_loss, targets)
            loss.backward()
            optimizer.step()

            total_loss += loss.detach().item()
            global_step += 1

            if (i + 1) % print_interval == 0 or (i + 1) == len(train_loader):
                current_lr = optimizer.param_groups[0]["lr"]
                # âœ… ì•ˆì „í•œ ê°’ ë³€í™˜ ì‚¬ìš© (tensor ë˜ëŠ” float ëª¨ë‘ ì²˜ë¦¬)
                loss_val = _safe_item(loss)
                
                # âœ… ì†ì‹¤ í•­ëª© ê°œìˆ˜ì— ë”°ë¥¸ ì ì‘ì  ì²˜ë¦¬
                if len(loss_items) == 3:
                    # FFCA-YOLO ìŠ¤íƒ€ì¼: [box, obj, cls]
                    total_loss_val = loss_val  # ì‹¤ì œ total loss ì‚¬ìš©
                    loop.set_postfix({
                        "Loss": f"{loss_val:.4f}",
                        "box": f"{_safe_item(loss_items[0]):.3f}",
                        "obj": f"{_safe_item(loss_items[1]):.3f}",
                        "cls": f"{_safe_item(loss_items[2]):.3f}",
                        "total": f"{total_loss_val:.3f}",
                        "lr": f"{current_lr:.6f}"
                    })
                elif len(loss_items) >= 4:
                    # ì¼ë°˜ì ì¸ YOLO ìŠ¤íƒ€ì¼: [box, obj, cls, total]
                    loop.set_postfix({
                        "Loss": f"{loss_val:.4f}",
                        "box": f"{_safe_item(loss_items[0]):.3f}",
                        "obj": f"{_safe_item(loss_items[1]):.3f}",
                        "cls": f"{_safe_item(loss_items[2]):.3f}",
                        "total": f"{_safe_item(loss_items[3]):.3f}",
                        "lr": f"{current_lr:.6f}"
                    })
                else:
                    # ì˜ˆì™¸ì ì¸ ê²½ìš°: ê¸°ë³¸ ì •ë³´ë§Œ í‘œì‹œ
                    loop.set_postfix({
                        "Loss": f"{loss_val:.4f}",
                        "lr": f"{current_lr:.6f}"
                    })

        scheduler.step()
        epoch_time = time.time() - start_time
        print(f"\n[{model_name}] âœ… Epoch {epoch+1}/{epochs} complete in {epoch_time:.2f}s | Avg Loss: {total_loss/len(train_loader):.4f}")

        # ğŸ” optional eval step
        if eval_fn:
            print(f"\n[{model_name}] ğŸ“Š Running evaluation after epoch {epoch+1} ...")
            ex_dict = eval_fn(ex_dict)

    return ex_dict
